{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _getOwnPropertyDescriptor = require('babel-runtime/core-js/object/get-own-property-descriptor');\n\nvar _getOwnPropertyDescriptor2 = _interopRequireDefault(_getOwnPropertyDescriptor);\n\nvar _deleteProperty = require('babel-runtime/core-js/reflect/delete-property');\n\nvar _deleteProperty2 = _interopRequireDefault(_deleteProperty);\n\nvar _assign = require('babel-runtime/core-js/object/assign');\n\nvar _assign2 = _interopRequireDefault(_assign);\n\nvar _toConsumableArray2 = require('babel-runtime/helpers/toConsumableArray');\n\nvar _toConsumableArray3 = _interopRequireDefault(_toConsumableArray2);\n\nvar _promise = require('babel-runtime/core-js/promise');\n\nvar _promise2 = _interopRequireDefault(_promise);\n\nvar _keys = require('babel-runtime/core-js/object/keys');\n\nvar _keys2 = _interopRequireDefault(_keys);\n\nvar _apply = require('babel-runtime/core-js/reflect/apply');\n\nvar _apply2 = _interopRequireDefault(_apply);\n\nvar _unset2 = require('lodash/unset');\n\nvar _unset3 = _interopRequireDefault(_unset2);\n\nvar _set2 = require('lodash/set');\n\nvar _set3 = _interopRequireDefault(_set2);\n\nvar _omit2 = require('lodash/omit');\n\nvar _omit3 = _interopRequireDefault(_omit2);\n\nvar _merge2 = require('lodash/merge');\n\nvar _merge3 = _interopRequireDefault(_merge2);\n\nvar _last2 = require('lodash/last');\n\nvar _last3 = _interopRequireDefault(_last2);\n\nvar _isString2 = require('lodash/isString');\n\nvar _isString3 = _interopRequireDefault(_isString2);\n\nvar _isFunction2 = require('lodash/isFunction');\n\nvar _isFunction3 = _interopRequireDefault(_isFunction2);\n\nvar _get2 = require('lodash/get');\n\nvar _get3 = _interopRequireDefault(_get2);\n\nvar _defaults2 = require('lodash/defaults');\n\nvar _defaults3 = _interopRequireDefault(_defaults2);\n\nvar _desc, _value, _obj;\n/*!\n * Copyright (c) 2015-2017 Cisco Systems, Inc. See LICENSE file.\n */\n\n\nexports.registerPlugin = registerPlugin;\nexports.registerInternalPlugin = registerInternalPlugin;\n\nvar _events = require('events');\n\nvar _util = require('util');\n\nvar _util2 = _interopRequireDefault(_util);\n\nvar _common = require('@webex/common');\n\nvar _httpCore = require('@webex/http-core');\n\nvar _ampersandState = require('ampersand-state');\n\nvar _ampersandState2 = _interopRequireDefault(_ampersandState);\n\nvar _uuid = require('uuid');\n\nvar _uuid2 = _interopRequireDefault(_uuid);\n\nvar _auth = require('./interceptors/auth');\n\nvar _auth2 = _interopRequireDefault(_auth);\n\nvar _networkTiming = require('./interceptors/network-timing');\n\nvar _networkTiming2 = _interopRequireDefault(_networkTiming);\n\nvar _payloadTransformer = require('./interceptors/payload-transformer');\n\nvar _payloadTransformer2 = _interopRequireDefault(_payloadTransformer);\n\nvar _redirect = require('./interceptors/redirect');\n\nvar _redirect2 = _interopRequireDefault(_redirect);\n\nvar _requestEvent = require('./interceptors/request-event');\n\nvar _requestEvent2 = _interopRequireDefault(_requestEvent);\n\nvar _requestLogger = require('./interceptors/request-logger');\n\nvar _requestLogger2 = _interopRequireDefault(_requestLogger);\n\nvar _requestTiming = require('./interceptors/request-timing');\n\nvar _requestTiming2 = _interopRequireDefault(_requestTiming);\n\nvar _responseLogger = require('./interceptors/response-logger');\n\nvar _responseLogger2 = _interopRequireDefault(_responseLogger);\n\nvar _sparkHttpError = require('./lib/spark-http-error');\n\nvar _sparkHttpError2 = _interopRequireDefault(_sparkHttpError);\n\nvar _sparkTrackingId = require('./interceptors/spark-tracking-id');\n\nvar _sparkTrackingId2 = _interopRequireDefault(_sparkTrackingId);\n\nvar _sparkUserAgent = require('./interceptors/spark-user-agent');\n\nvar _sparkUserAgent2 = _interopRequireDefault(_sparkUserAgent);\n\nvar _rateLimit = require('./interceptors/rate-limit');\n\nvar _rateLimit2 = _interopRequireDefault(_rateLimit);\n\nvar _config = require('./config');\n\nvar _config2 = _interopRequireDefault(_config);\n\nvar _storage = require('./lib/storage');\n\nvar _sparkCorePluginMixin = require('./lib/spark-core-plugin-mixin');\n\nvar _sparkCorePluginMixin2 = _interopRequireDefault(_sparkCorePluginMixin);\n\nvar _sparkInternalCorePluginMixin = require('./lib/spark-internal-core-plugin-mixin');\n\nvar _sparkInternalCorePluginMixin2 = _interopRequireDefault(_sparkInternalCorePluginMixin);\n\nvar _sparkInternalCore = require('./spark-internal-core');\n\nvar _sparkInternalCore2 = _interopRequireDefault(_sparkInternalCore);\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\nfunction _applyDecoratedDescriptor(target, property, decorators, descriptor, context) {\n  var desc = {};\n  Object['ke' + 'ys'](descriptor).forEach(function (key) {\n    desc[key] = descriptor[key];\n  });\n  desc.enumerable = !!desc.enumerable;\n  desc.configurable = !!desc.configurable;\n\n  if ('value' in desc || desc.initializer) {\n    desc.writable = true;\n  }\n\n  desc = decorators.slice().reverse().reduce(function (desc, decorator) {\n    return decorator(target, property, desc) || desc;\n  }, desc);\n\n  if (context && desc.initializer !== void 0) {\n    desc.value = desc.initializer ? desc.initializer.call(context) : void 0;\n    desc.initializer = undefined;\n  }\n\n  if (desc.initializer === void 0) {\n    Object['define' + 'Property'](target, property, desc);\n    desc = null;\n  }\n\n  return desc;\n} // TODO replace the Interceptor.create with Reflect.construct (\n// Interceptor.create exists because new was really hard to call on an array of\n// constructors)\n\n\nvar interceptors = {\n  SparkTrackingIdInterceptor: _sparkTrackingId2.default.create,\n  RequestEventInterceptor: _requestEvent2.default.create,\n  RateLimitInterceptor: _rateLimit2.default.create,\n\n  /* eslint-disable no-extra-parens */\n  RequestLoggerInterceptor: process.env.ENABLE_NETWORK_LOGGING || process.env.ENABLE_VERBOSE_NETWORK_LOGGING ? _requestLogger2.default.create : undefined,\n  ResponseLoggerInterceptor: process.env.ENABLE_NETWORK_LOGGING || process.env.ENABLE_VERBOSE_NETWORK_LOGGING ? _responseLogger2.default.create : undefined,\n\n  /* eslint-enable no-extra-parens */\n  RequestTimingInterceptor: _requestTiming2.default.create,\n  UrlInterceptor: undefined,\n  SparkUserAgentInterceptor: _sparkUserAgent2.default.create,\n  AuthInterceptor: _auth2.default.create,\n  KmsDryErrorInterceptor: undefined,\n  PayloadTransformerInterceptor: _payloadTransformer2.default.create,\n  ConversationInterceptor: undefined,\n  RedirectInterceptor: _redirect2.default.create,\n  HttpStatusInterceptor: function HttpStatusInterceptor() {\n    return _httpCore.HttpStatusInterceptor.create({\n      error: _sparkHttpError2.default\n    });\n  },\n  NetworkTimingInterceptor: _networkTiming2.default.create\n};\nvar preInterceptors = ['ResponseLoggerInterceptor', 'RequestTimingInterceptor', 'RequestEventInterceptor', 'SparkTrackingIdInterceptor', 'RateLimitInterceptor'];\nvar postInterceptors = ['HttpStatusInterceptor', 'NetworkTimingInterceptor', 'RequestLoggerInterceptor', 'RateLimitInterceptor'];\n/**\n * @class\n */\n\nvar SparkCore = _ampersandState2.default.extend((_obj = {\n  version: '1.59.0',\n  children: {\n    internal: _sparkInternalCore2.default\n  },\n  constructor: function constructor() {\n    var attrs = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    var options = arguments[1];\n\n    if (typeof attrs === 'string') {\n      attrs = {\n        credentials: {\n          supertoken: {\n            // eslint-disable-next-line camelcase\n            access_token: attrs\n          }\n        }\n      };\n    } else {\n      // Reminder: order is important here\n      ['credentials.authorization', 'authorization', 'credentials.supertoken.supertoken', 'supertoken', 'access_token', 'credentials.authorization.supertoken'].forEach(function (path) {\n        var val = (0, _get3.default)(attrs, path);\n\n        if (val) {\n          (0, _unset3.default)(attrs, path);\n          (0, _set3.default)(attrs, 'credentials.supertoken', val);\n        }\n      });\n      ['credentials', 'credentials.authorization'].forEach(function (path) {\n        var val = (0, _get3.default)(attrs, path);\n\n        if (typeof val === 'string') {\n          (0, _unset3.default)(attrs, path);\n          (0, _set3.default)(attrs, 'credentials.supertoken', val);\n        }\n      });\n\n      if (typeof (0, _get3.default)(attrs, 'credentials.access_token') === 'string') {\n        // Send access_token to get validated and corrected and then set it\n        (0, _set3.default)(attrs, 'credentials.access_token', this.bearerValidator((0, _get3.default)(attrs, 'credentials.access_token').trim()));\n        (0, _set3.default)(attrs, 'credentials.supertoken', attrs.credentials);\n      }\n    }\n\n    return (0, _apply2.default)(_ampersandState2.default, this, [attrs, options]);\n  },\n  derived: {\n    boundedStorage: {\n      deps: [],\n      fn: function fn() {\n        return (0, _storage.makeSparkStore)('bounded', this);\n      }\n    },\n    unboundedStorage: {\n      deps: [],\n      fn: function fn() {\n        return (0, _storage.makeSparkStore)('unbounded', this);\n      }\n    },\n    ready: {\n      deps: ['loaded', 'internal.ready'],\n      fn: function fn() {\n        var _this = this;\n\n        return this.loaded && (0, _keys2.default)(this._children).reduce(function (ready, name) {\n          return ready && _this[name] && _this[name].ready !== false;\n        }, true);\n      }\n    }\n  },\n  session: {\n    config: {\n      type: 'object'\n    },\n\n    /**\n     * When true, indicates that the initial load from the storage layer is\n     * complete\n     * @instance\n     * @memberof SparkCore\n     * @type {boolean}\n     */\n    loaded: {\n      default: false,\n      type: 'boolean'\n    },\n    request: {\n      setOnce: true,\n      // It's supposed to be a function, but that's not a type defined in\n      // Ampersand\n      type: 'any'\n    },\n    sessionId: {\n      setOnce: true,\n      type: 'string'\n    }\n  },\n\n  /**\n   * @instance\n   * @memberof SparkCore\n   * @param {[type]} args\n   * @returns {[type]}\n   */\n  refresh: function refresh() {\n    var _credentials;\n\n    return (_credentials = this.credentials).refresh.apply(_credentials, arguments);\n  },\n\n  /**\n   * Applies the directionally appropriate transforms to the specified object\n   * @param {string} direction\n   * @param {Object} object\n   * @returns {Promise}\n   */\n  transform: function transform(direction, object) {\n    var _this2 = this;\n\n    var predicates = this.config.payloadTransformer.predicates.filter(function (p) {\n      return !p.direction || p.direction === direction;\n    });\n    var ctx = {\n      spark: this\n    };\n    return _promise2.default.all(predicates.map(function (p) {\n      return p.test(ctx, object).then(function (shouldTransform) {\n        if (!shouldTransform) {\n          return undefined;\n        }\n\n        return p.extract(object) // eslint-disable-next-line max-nested-callbacks\n        .then(function (target) {\n          return {\n            name: p.name,\n            target: target\n          };\n        });\n      });\n    })).then(function (data) {\n      return data.filter(function (d) {\n        return Boolean(d);\n      }) // eslint-disable-next-line max-nested-callbacks\n      .reduce(function (promise, _ref) {\n        var name = _ref.name,\n            target = _ref.target,\n            alias = _ref.alias;\n        return promise.then(function () {\n          if (alias) {\n            return _this2.applyNamedTransform(direction, alias, target);\n          }\n\n          return _this2.applyNamedTransform(direction, name, target);\n        });\n      }, _promise2.default.resolve());\n    }).then(function () {\n      return object;\n    });\n  },\n\n  /**\n   * Applies the directionally appropriate transform to the specified parameters\n   * @param {string} direction\n   * @param {Object} ctx\n   * @param {string} name\n   * @returns {Promise}\n   */\n  applyNamedTransform: function applyNamedTransform(direction, ctx, name) {\n    for (var _len = arguments.length, rest = Array(_len > 3 ? _len - 3 : 0), _key = 3; _key < _len; _key++) {\n      rest[_key - 3] = arguments[_key];\n    }\n\n    var _this3 = this;\n\n    if ((0, _isString3.default)(ctx)) {\n      rest.unshift(name);\n      name = ctx;\n      ctx = {\n        spark: this,\n        transform: function transform() {\n          for (var _len2 = arguments.length, args = Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n            args[_key2] = arguments[_key2];\n          }\n\n          return _this3.applyNamedTransform.apply(_this3, [direction, ctx].concat(args));\n        }\n      };\n    }\n\n    var transforms = ctx.spark.config.payloadTransformer.transforms.filter(function (tx) {\n      return tx.name === name && (!tx.direction || tx.direction === direction);\n    }); // too many implicit returns on the same line is difficult to interpret\n    // eslint-disable-next-line arrow-body-style\n\n    return transforms.reduce(function (promise, tx) {\n      return promise.then(function () {\n        if (tx.alias) {\n          var _ctx;\n\n          return (_ctx = ctx).transform.apply(_ctx, [tx.alias].concat((0, _toConsumableArray3.default)(rest)));\n        }\n\n        return _promise2.default.resolve(tx.fn.apply(tx, [ctx].concat((0, _toConsumableArray3.default)(rest))));\n      });\n    }, _promise2.default.resolve()).then(function () {\n      return (0, _last3.default)(rest);\n    });\n  },\n\n  /**\n   * @private\n   * @returns {Window}\n   */\n  getWindow: function getWindow() {\n    // eslint-disable-next-line\n    return window;\n  },\n\n  /**\n   * Initializer\n   *\n   * @emits SparkCore#loaded\n   * @emits SparkCore#ready\n   * @instance\n   * @memberof SparkCore\n   * @param {Object} attrs\n   * @returns {SparkCore}\n   */\n  initialize: function initialize() {\n    var _this4 = this;\n\n    var attrs = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {}; // Ensure federation is disabled on init\n\n    delete _config2.default.credentials.federation;\n    this.config = (0, _merge3.default)({}, _config2.default, attrs.config); // There's some unfortunateness with the way {@link AmpersandState#children}\n    // get initialized. We'll fire the change:config event so that\n    // {@link SparkPlugin#initialize()} can use\n    // `this.listenToOnce(parent, 'change:config', () => {});` to act on config\n    // during initialization\n\n    this.trigger('change:config');\n\n    var onLoaded = function onLoaded() {\n      if (_this4.loaded) {\n        /**\n         * Fires when all data has been loaded from the storage layer\n         * @event loaded\n         * @instance\n         * @memberof SparkCore\n         */\n        _this4.trigger('loaded');\n\n        _this4.stopListening(_this4, 'change:loaded', onLoaded);\n      }\n    }; // This needs to run on nextTick or we'll never be able to wire up listeners\n\n\n    process.nextTick(function () {\n      _this4.listenToAndRun(_this4, 'change:loaded', onLoaded);\n    });\n\n    var onReady = function onReady() {\n      if (_this4.ready) {\n        /**\n         * Fires when all plugins have fully initialized\n         * @event ready\n         * @instance\n         * @memberof SparkCore\n         */\n        _this4.trigger('ready');\n\n        _this4.stopListening(_this4, 'change:ready', onReady);\n      }\n    }; // This needs to run on nextTick or we'll never be able to wire up listeners\n\n\n    process.nextTick(function () {\n      _this4.listenToAndRun(_this4, 'change:ready', onReady);\n    }); // Make nested events propagate in a consistent manner\n\n    (0, _keys2.default)(this.constructor.prototype._children).forEach(function (key) {\n      _this4.listenTo(_this4[key], 'change', function () {\n        for (var _len3 = arguments.length, args = Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {\n          args[_key3] = arguments[_key3];\n        }\n\n        args.unshift('change:' + key);\n\n        _this4.trigger.apply(_this4, args);\n      });\n    });\n\n    var addInterceptor = function addInterceptor(ints, key) {\n      var interceptor = interceptors[key];\n\n      if (!(0, _isFunction3.default)(interceptor)) {\n        return ints;\n      }\n\n      ints.push((0, _apply2.default)(interceptor, _this4, []));\n      return ints;\n    };\n\n    var ints = [];\n    ints = preInterceptors.reduce(addInterceptor, ints);\n    ints = (0, _keys2.default)(interceptors).filter(function (key) {\n      return !(preInterceptors.includes(key) || postInterceptors.includes(key));\n    }).reduce(addInterceptor, ints);\n    ints = postInterceptors.reduce(addInterceptor, ints);\n    this.request = (0, _httpCore.defaults)({\n      json: true,\n      interceptors: ints\n    });\n    var sessionId = (0, _get3.default)(this, 'config.trackingIdPrefix', 'spark-js-sdk') + '_' + (0, _get3.default)(this, 'config.trackingIdBase', _uuid2.default.v4());\n\n    if ((0, _get3.default)(this, 'config.trackingIdSuffix')) {\n      sessionId += '_' + (0, _get3.default)(this, 'config.trackingIdSuffix');\n    }\n\n    this.sessionId = sessionId;\n  },\n\n  /**\n   * setConfig\n   *\n   * Allows updating config\n   *\n   * @instance\n   * @memberof SparkCore\n   * @param {Object} newConfig\n   * @returns {null}\n   */\n  setConfig: function setConfig() {\n    var newConfig = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    this.config = (0, _merge3.default)({}, this.config, newConfig);\n  },\n\n  /**\n   *\n   * Check if access token is correctly formated and correct if it's not\n   * Warn user if token string has errors in it\n   * @param {string} token\n   * @returns {string}\n   */\n  bearerValidator: function bearerValidator(token) {\n    if (token.includes('Bearer') && token.split(' ').length - 1 === 0) {\n      console.warn('Your access token does not have a space between \\'Bearer\\' and the token, please add a space to it or replace it with this already fixed version:\\n\\n' + token.replace('Bearer', 'Bearer ').replace(/\\s+/g, ' '));\n      console.info(\"Tip: You don't need to add 'Bearer' to the access_token field. The token by itself is fine\");\n      return token.replace('Bearer', 'Bearer ').replace(/\\s+/g, ' ');\n    } // Allow elseIf return\n    // eslint-disable-next-line  no-else-return\n    else if (token.split(' ').length - 1 > 1) {\n        console.warn('Your access token has ' + (token.split(' ').length - 2) + ' too many spaces, please use this format:\\n\\n' + token.replace(/\\s+/g, ' '));\n        console.info(\"Tip: You don't need to add 'Bearer' to the access_token field, the token by itself is fine\");\n        return token.replace(/\\s+/g, ' ');\n      }\n\n    return token.replace(/\\s+/g, ' '); // Clean it anyway (just in case)\n  },\n\n  /**\n   * @instance\n   * @memberof SparkPlugin\n   * @param {number} depth\n   * @private\n   * @returns {Object}\n   */\n  inspect: function inspect(depth) {\n    return _util2.default.inspect((0, _omit3.default)(this.serialize({\n      props: true,\n      session: true,\n      derived: true\n    }), 'boundedStorage', 'unboundedStorage', 'request', 'config'), {\n      depth: depth\n    });\n  },\n\n  /**\n   * Invokes all `onBeforeLogout` handlers in the scope of their plugin, clears\n   * all stores, and revokes the access token\n   * Note: If you're using the sdk in a server environment, you may be more\n   * interested in {@link `spark.internal.mercury.disconnect()`| Mercury#disconnect()}\n   * and {@link `spark.internal.device.unregister()`|Device#unregister()}\n   * or {@link `spark.phone.unregister()`|Phone#unregister}\n   * @instance\n   * @memberof SparkCore\n   * @param {Object} options Passed as the first argument to all\n   * `onBeforeLogout` handlers\n   * @returns {Promise}\n   */\n  logout: function logout(options) {\n    var _this5 = this;\n\n    for (var _len4 = arguments.length, rest = Array(_len4 > 1 ? _len4 - 1 : 0), _key4 = 1; _key4 < _len4; _key4++) {\n      rest[_key4 - 1] = arguments[_key4];\n    } // prefer the refresh token, but for clients that don't have one, fallback\n    // to the access token\n\n\n    var token = this.credentials.supertoken && (this.credentials.supertoken.refresh_token || this.credentials.supertoken.access_token);\n    options = (0, _assign2.default)({\n      token: token\n    }, options); // onBeforeLogout should be executed in the opposite order in which handlers\n    // were registered. In that way, wdm unregister() will be above mercury\n    // disconnect(), but disconnect() will execute first.\n    // eslint-disable-next-line arrow-body-style\n\n    return this.config.onBeforeLogout.reverse().reduce(function (promise, _ref2) {\n      var plugin = _ref2.plugin,\n          fn = _ref2.fn;\n      return promise.then(function () {\n        return _promise2.default.resolve((0, _apply2.default)(fn, _this5[plugin] || _this5.internal[plugin], [options].concat((0, _toConsumableArray3.default)(rest)))) // eslint-disable-next-line max-nested-callbacks\n        .catch(function (err) {\n          _this5.logger.warn('onBeforeLogout from plugin ' + plugin + ': failed', err);\n        });\n      });\n    }, _promise2.default.resolve()).then(function () {\n      return _promise2.default.all([_this5.boundedStorage.clear(), _this5.unboundedStorage.clear()]);\n    }).then(function () {\n      var _credentials2;\n\n      return (_credentials2 = _this5.credentials).invalidate.apply(_credentials2, (0, _toConsumableArray3.default)(rest));\n    }).then(function () {\n      var _authorization;\n\n      return _this5.authorization && _this5.authorization.logout && (_authorization = _this5.authorization).logout.apply(_authorization, [options].concat((0, _toConsumableArray3.default)(rest)));\n    }).then(function () {\n      return _this5.trigger('client:logout');\n    });\n  },\n\n  /**\n   * General purpose wrapper to submit metrics via the metrics plugin (if the\n   * metrics plugin is installed)\n   * @instance\n   * @memberof SparkCore\n   * @returns {Promise}\n   */\n  measure: function measure() {\n    if (this.metrics) {\n      var _metrics;\n\n      return (_metrics = this.metrics).sendUnstructured.apply(_metrics, arguments);\n    }\n\n    return _promise2.default.resolve();\n  },\n  upload: function upload(options) {\n    var _this6 = this;\n\n    if (!options.file) {\n      return _promise2.default.reject(new Error('`options.file` is required'));\n    }\n\n    options.phases = options.phases || {};\n    options.phases.initialize = options.phases.initialize || {};\n    options.phases.upload = options.phases.upload || {};\n    options.phases.finalize = options.phases.finalize || {};\n    (0, _defaults3.default)(options.phases.initialize, {\n      method: 'POST'\n    }, (0, _omit3.default)(options, 'file', 'phases'));\n    (0, _defaults3.default)(options.phases.upload, {\n      method: 'PUT',\n      json: false,\n      withCredentials: false,\n      body: options.file,\n      headers: {\n        'x-trans-id': _uuid2.default.v4(),\n        authorization: undefined\n      }\n    });\n    (0, _defaults3.default)(options.phases.finalize, {\n      method: 'POST'\n    }, (0, _omit3.default)(options, 'file', 'phases'));\n    var shunt = new _events.EventEmitter();\n\n    var promise = this._uploadPhaseInitialize(options).then(function () {\n      var p = _this6._uploadPhaseUpload(options);\n\n      (0, _common.transferEvents)('progress', p, shunt);\n      return p;\n    }).then(function () {\n      for (var _len5 = arguments.length, args = Array(_len5), _key5 = 0; _key5 < _len5; _key5++) {\n        args[_key5] = arguments[_key5];\n      }\n\n      return _this6._uploadPhaseFinalize.apply(_this6, [options].concat(args));\n    }).then(function (res) {\n      return res.body;\n    });\n\n    (0, _common.proxyEvents)(shunt, promise);\n    return promise;\n  },\n  _uploadPhaseInitialize: function _uploadPhaseInitialize(options) {\n    var _this7 = this;\n\n    this.logger.debug('client: initiating upload session');\n    return this.request(options.phases.initialize).then(function () {\n      for (var _len6 = arguments.length, args = Array(_len6), _key6 = 0; _key6 < _len6; _key6++) {\n        args[_key6] = arguments[_key6];\n      }\n\n      return _this7._uploadApplySession.apply(_this7, [options].concat(args));\n    }).then(function (res) {\n      _this7.logger.debug('client: initiated upload session');\n\n      return res;\n    });\n  },\n  _uploadApplySession: function _uploadApplySession(options, res) {\n    var session = res.body;\n    ['upload', 'finalize'].reduce(function (opts, key) {\n      opts[key] = (0, _keys2.default)(opts[key]).reduce(function (phaseOptions, phaseKey) {\n        if (phaseKey.startsWith('$')) {\n          phaseOptions[phaseKey.substr(1)] = phaseOptions[phaseKey](session);\n          (0, _deleteProperty2.default)(phaseOptions, phaseKey);\n        }\n\n        return phaseOptions;\n      }, opts[key]);\n      return opts;\n    }, options.phases);\n  },\n  _uploadPhaseUpload: function _uploadPhaseUpload(options) {\n    var _this8 = this;\n\n    this.logger.debug('client: uploading file');\n    var promise = this.request(options.phases.upload).then(function (res) {\n      _this8.logger.debug('client: uploaded file');\n\n      return res;\n    });\n    (0, _common.proxyEvents)(options.phases.upload.upload, promise);\n    /* istanbul ignore else */\n\n    if (process.env.NODE_ENV === 'test') {\n      promise.on('progress', function (event) {\n        _this8.logger.info('upload progress', event.loaded, event.total);\n      });\n    }\n\n    return promise;\n  },\n  _uploadPhaseFinalize: function _uploadPhaseFinalize(options) {\n    var _this9 = this;\n\n    this.logger.debug('client: finalizing upload session');\n    return this.request(options.phases.finalize).then(function (res) {\n      _this9.logger.debug('client: finalized upload session');\n\n      return res;\n    });\n  }\n}, _applyDecoratedDescriptor(_obj, '_uploadPhaseUpload', [_common.retry], (0, _getOwnPropertyDescriptor2.default)(_obj, '_uploadPhaseUpload'), _obj), _obj));\n\nSparkCore.version = '1.59.0';\n(0, _sparkInternalCorePluginMixin2.default)(_sparkInternalCore2.default, _config2.default, interceptors);\n(0, _sparkCorePluginMixin2.default)(SparkCore, _config2.default, interceptors);\nexports.default = SparkCore;\n/**\n * @method registerPlugin\n * @param {string} name\n * @param {function} constructor\n * @param {Object} options\n * @param {Array<string>} options.proxies\n * @param {Object} options.interceptors\n * @returns {null}\n */\n\nfunction registerPlugin(name, constructor, options) {\n  SparkCore.registerPlugin(name, constructor, options);\n}\n/**\n * Registers plugins used by internal products that do not talk to public APIs.\n * @method registerInternalPlugin\n * @param {string} name\n * @param {function} constructor\n * @param {Object} options\n * @param {Object} options.interceptors\n * @private\n * @returns {null}\n */\n\n\nfunction registerInternalPlugin(name, constructor, options) {\n  _sparkInternalCore2.default.registerPlugin(name, constructor, options);\n}","map":null,"metadata":{},"sourceType":"script"}