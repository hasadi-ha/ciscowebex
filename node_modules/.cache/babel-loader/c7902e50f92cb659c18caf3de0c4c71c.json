{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar _getOwnPropertyDescriptor = require('babel-runtime/core-js/object/get-own-property-descriptor');\n\nvar _getOwnPropertyDescriptor2 = _interopRequireDefault(_getOwnPropertyDescriptor);\n\nvar _map = require('babel-runtime/core-js/map');\n\nvar _map2 = _interopRequireDefault(_map);\n\nvar _classCallCheck2 = require('babel-runtime/helpers/classCallCheck');\n\nvar _classCallCheck3 = _interopRequireDefault(_classCallCheck2);\n\nvar _createClass2 = require('babel-runtime/helpers/createClass');\n\nvar _createClass3 = _interopRequireDefault(_createClass2);\n\nvar _keys = require('babel-runtime/core-js/object/keys');\n\nvar _keys2 = _interopRequireDefault(_keys);\n\nvar _weakMap = require('babel-runtime/core-js/weak-map');\n\nvar _weakMap2 = _interopRequireDefault(_weakMap);\n\nvar _result2 = require('lodash/result');\n\nvar _result3 = _interopRequireDefault(_result2);\n\nvar _isObject2 = require('lodash/isObject');\n\nvar _isObject3 = _interopRequireDefault(_isObject2);\n\nvar _isArray2 = require('lodash/isArray');\n\nvar _isArray3 = _interopRequireDefault(_isArray2);\n\nexports.default = makeSparkPluginStorage;\n\nvar _common = require('@webex/common');\n\nvar _errors = require('./errors');\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\nfunction _applyDecoratedDescriptor(target, property, decorators, descriptor, context) {\n  var desc = {};\n  Object['ke' + 'ys'](descriptor).forEach(function (key) {\n    desc[key] = descriptor[key];\n  });\n  desc.enumerable = !!desc.enumerable;\n  desc.configurable = !!desc.configurable;\n\n  if ('value' in desc || desc.initializer) {\n    desc.writable = true;\n  }\n\n  desc = decorators.slice().reverse().reduce(function (desc, decorator) {\n    return decorator(target, property, desc) || desc;\n  }, desc);\n\n  if (context && desc.initializer !== void 0) {\n    desc.value = desc.initializer ? desc.initializer.call(context) : void 0;\n    desc.initializer = undefined;\n  }\n\n  if (desc.initializer === void 0) {\n    Object['define' + 'Property'](target, property, desc);\n    desc = null;\n  }\n\n  return desc;\n}\n/*!\n * Copyright (c) 2015-2017 Cisco Systems, Inc. See LICENSE file.\n */\n\n\nvar defers = new _weakMap2.default();\n/**\n * Walks an object before writing it to the store and omits empty arrays\n * @private\n * @param {Object} value\n * @returns {Object}\n */\n\nfunction serialize(value) {\n  if (!(0, _isObject3.default)(value)) {\n    return value;\n  }\n\n  var serialized = value.serialize ? value.serialize() : value;\n  (0, _keys2.default)(serialized).forEach(function (key) {\n    var val = serialized[key];\n\n    if ((0, _isArray3.default)(val)) {\n      if (val.length === 0) {\n        serialized[key] = undefined;\n      } else {\n        serialized[key] = val.map(serialize);\n      }\n    } else if ((0, _isObject3.default)(val)) {\n      (0, _keys2.default)(val).forEach(function (k) {\n        val[k] = serialize(val[k]);\n      });\n    }\n  });\n  var empty = (0, _keys2.default)(serialized).reduce(function (acc, key) {\n    return acc && !serialized[key];\n  }, true);\n\n  if (empty) {\n    return undefined;\n  }\n\n  return serialized;\n}\n/**\n * [makeSparkPluginStorage description]\n * @param {[type]} type\n * @param {[type]} context\n * @private\n * @returns {[type]}\n */\n\n\nfunction makeSparkPluginStorage(type, context) {\n  var _dec, _desc, _value, _class;\n  /**\n   * Interface between SparkPlugin and Spark#boundeStorage or\n   * Spark#unboundedStorage\n   */\n\n\n  var SparkPluginStorage = (_dec = (0, _common.oneFlight)({\n    keyFactory: function keyFactory(key) {\n      return 'initValue-' + key;\n    }\n  }), (_class = function () {\n    /**\n     * @param {Object} attrs\n     * @param {Object} options\n     * @returns {SparkPluginStorage}\n     */\n    function SparkPluginStorage() {\n      (0, _classCallCheck3.default)(this, SparkPluginStorage);\n      defers.set(this, new _map2.default());\n    }\n    /**\n     * Clears an entire namespace\n     * @returns {Promise}\n     */\n\n\n    (0, _createClass3.default)(SparkPluginStorage, [{\n      key: 'clear',\n      value: function clear() {\n        return context.spark[type + 'Storage'].del(context.getNamespace());\n      }\n      /**\n       * Deletes the specified key from the store\n       * @param {string} key\n       * @returns {[type]}\n       */\n\n    }, {\n      key: 'del',\n      value: function del() {\n        var _context$spark$;\n\n        for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {\n          args[_key] = arguments[_key];\n        }\n\n        return (_context$spark$ = context.spark[type + 'Storage']).del.apply(_context$spark$, [context.getNamespace()].concat(args));\n      }\n      /**\n       * Retrieves the value specified by key from the store. Rejects with\n       * NotFoundError if no value can be found\n       * @param {string} key\n       * @returns {Promise}\n       */\n\n    }, {\n      key: 'get',\n      value: function get(key) {\n        var defer = defers.get(this).get(key);\n\n        if (!defer) {\n          defer = new _common.Defer();\n          defers.get(this).set(key, defer);\n        }\n\n        return context.spark[type + 'Storage'].get(context.getNamespace(), key).then(function (res) {\n          defer.resolve();\n          return res;\n        });\n      }\n      /**\n       * Writes a value to the store\n       * @param {string} key\n       * @param {any} value\n       * @returns {Promise}\n       */\n\n    }, {\n      key: 'put',\n      value: function put(key, value) {\n        return context.spark[type + 'Storage'].put(context.getNamespace(), key, serialize(value));\n      }\n      /**\n       * Returns a Promise that won't resolve until the value specified by key has\n       * been attempted to be loaded from the store. This allows us to lazily\n       * prevent certain method from executing until the specified keys have been\n       * retrieved from the store.\n       * @param {string} key\n       * @returns {Promise}\n       */\n\n    }, {\n      key: 'waitFor',\n      value: function waitFor(key) {\n        context.logger.debug('plugin-storage(' + context.getNamespace() + '): waiting to init key `' + key + '`');\n        var defer = defers.get(this).get(key);\n\n        if (defer) {\n          context.logger.debug('plugin-storage(' + context.getNamespace() + '): already inited `' + key + '`');\n          return defer.promise;\n        }\n\n        context.logger.debug('plugin-storage(' + context.getNamespace() + '): initing `' + key + '`');\n        return this.initValue(key);\n      }\n    }, {\n      key: 'initValue',\n\n      /**\n       * Attempts to load the specified key from the store and set it on the parent\n       * object.\n       * @param {string} key\n       * @returns {Promise} Resolves (but not with the retrieved value) when\n       * the value retrieval complete\n       */\n      // suppress doc warning because decorators confuse eslint\n      // eslint-disable-next-line require-jsdoc\n      value: function initValue(key) {\n        var defer = new _common.Defer();\n        defers.get(this).set(key, defer); // Intentionally bypasses this.get so we don't resolve the promise until\n        // after the parent value is set.\n\n        context.spark[type + 'Storage'].get(context.getNamespace(), key).then(function (value) {\n          context.logger.debug('plugin-storage(' + context.getNamespace() + '): got `' + key + '` for first time');\n\n          if (key === '@') {\n            context.parent.set(value);\n          } else if ((0, _result3.default)(context[key], 'isState')) {\n            context[key].set(value);\n          } else {\n            context.set(key, value);\n          }\n\n          context.logger.debug('plugin-storage(' + context.getNamespace() + '): set `' + key + '` for first time');\n          defer.resolve();\n          context.logger.debug('plugin-storage(' + context.getNamespace() + '): inited `' + key + '`');\n        }).catch(function (reason) {\n          // The  next conditional is a bit of an unfortunate solution to deal\n          // with circular dependencies in unit tests. It should not effect\n          // integration tests or production code.\n          if (reason instanceof _errors.NotFoundError || process.env.NODE_ENV !== 'production' && reason.toString().includes('MockNotFoundError')) {\n            context.logger.debug('plugin-storage(' + context.getNamespace() + '): no data for `' + key + '`, continuing');\n            return defer.resolve();\n          }\n\n          context.logger.warn('plugin-storage(' + context.getNamespace() + '): failed to init `' + key + '`', reason);\n          return defer.reject(reason);\n        });\n        return defer.promise;\n      }\n    }]);\n    return SparkPluginStorage;\n  }(), _applyDecoratedDescriptor(_class.prototype, 'initValue', [_dec], (0, _getOwnPropertyDescriptor2.default)(_class.prototype, 'initValue'), _class.prototype), _class));\n  return new SparkPluginStorage();\n}","map":null,"metadata":{},"sourceType":"script"}